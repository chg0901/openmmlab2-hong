{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0a25e6-6f49-4f96-af23-b1e81fb10ab4",
   "metadata": {},
   "source": [
    "# 预训练语义分割模型预测-视频\n",
    "\n",
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "2022-10-18 6-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545b852-5e69-45b6-abbc-1483b7a434d6",
   "metadata": {},
   "source": [
    "## 进入 mmsegmentation 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e564fa3-cabb-49e9-b721-163e162fbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cine/Documents/GitHub/MMSeg_tutorial\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24d56aa-5528-4561-bb1c-33bcffe2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../mmsegmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fb7cdd-ccdc-44fe-a975-1d91d21673ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cine/Documents/GitHub/mmsegmentation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3673e-a5f2-46f0-a87f-0069dd165485",
   "metadata": {},
   "source": [
    "## 视频预测-命令行（不推荐，慢）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792ec8de-1785-4d72-9f6f-704f596b6519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "/home/cine/Documents/GitHub/mmdet/mmdetection/mmdet/models/layers/positional_encoding.py:84: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "06/14 12:40:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `Visualizer` backend is not initialized because save_dir is None.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"demo/video_demo.py\", line 112, in <module>\n",
      "    main()\n",
      "  File \"demo/video_demo.py\", line 94, in main\n",
      "    draw_img = show_result_pyplot(model, frame, result)\n",
      "  File \"/home/cine/Documents/GitHub/mmsegmentation/mmseg/apis/inference.py\", line 203, in show_result_pyplot\n",
      "    visualizer.add_datasample(\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/mmengine/dist/utils.py\", line 360, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/cine/Documents/GitHub/mmsegmentation/mmseg/visualization/local_visualizer.py\", line 214, in add_datasample\n",
      "    pred_img_data = self._draw_sem_seg(pred_img_data,\n",
      "  File \"/home/cine/Documents/GitHub/mmsegmentation/mmseg/visualization/local_visualizer.py\", line 115, in _draw_sem_seg\n",
      "    self.draw_binary_masks(\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/mmengine/dist/utils.py\", line 360, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/mmengine/visualization/visualizer.py\", line 859, in draw_binary_masks\n",
      "    img = self.get_image()\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/mmengine/dist/utils.py\", line 360, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/mmengine/visualization/visualizer.py\", line 297, in get_image\n",
      "    return img_from_canvas(self.fig_save_canvas)  # type: ignore\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/mmengine/visualization/utils.py\", line 240, in img_from_canvas\n",
      "    s, (width, height) = canvas.print_to_buffer()\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 512, in print_to_buffer\n",
      "    FigureCanvasAgg.draw(self)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 400, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/figure.py\", line 3140, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/axes/_base.py\", line 3064, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/image.py\", line 641, in draw\n",
      "    im, l, b, trans = self.make_image(\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/image.py\", line 949, in make_image\n",
      "    return self._make_image(self._A, bbox, transformed_bbox, clip,\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/image.py\", line 553, in _make_image\n",
      "    output_alpha = _resample(  # resample alpha channel\n",
      "  File \"/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/matplotlib/image.py\", line 207, in _resample\n",
      "    _image.resample(data, out, transform,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python demo/video_demo.py \\\n",
    "        data/street_20220330_174028.mp4 \\\n",
    "        configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py \\\n",
    "        https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth \\\n",
    "        --device cuda:0 \\\n",
    "        --output-file outputs/B3_video.mp4 \\\n",
    "        --opacity 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd646001-89ad-4508-b709-717a18230316",
   "metadata": {},
   "source": [
    "## 视频预测-Python API（推荐，快）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fbae8-e700-41f4-8b75-c01224883dee",
   "metadata": {},
   "source": [
    "### 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75bdbf74-66bb-4e0e-abb1-6e4f48a7f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import mmengine\n",
    "from mmseg.apis import inference_model\n",
    "from mmseg.utils import register_all_modules\n",
    "register_all_modules()\n",
    "\n",
    "from mmseg.datasets import CityscapesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ff19c-ae76-4203-aa61-b2c2f105c6ad",
   "metadata": {},
   "source": [
    "### 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6710ee9f-d7b9-4ca7-ba84-84499ec5353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型 config 配置文件\n",
    "config_file = 'configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py'\n",
    "\n",
    "# 模型 checkpoint 权重文件\n",
    "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c891afa1-1f5f-4a16-ae38-97b72c5966a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import init_model\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "from mmengine.model.utils import revert_sync_batchnorm\n",
    "if not torch.cuda.is_available():\n",
    "    model = revert_sync_batchnorm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81912ec-c8ff-4d63-8c4b-f0b9eab00da7",
   "metadata": {},
   "source": [
    "### 输入视频路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ae61f8-23ec-4f99-8951-ebc1522280b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_video = 'data/traffic.mp4'\n",
    "\n",
    "input_video = 'data/street_20220330_174028.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3f035-8390-4be4-aefe-770990a04f78",
   "metadata": {},
   "source": [
    "### 创建临时文件夹，存放每帧结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d92a9e1-040d-4c4b-881d-f16053086db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建临时文件夹 20230614125150 用于存放每帧预测结果\n"
     ]
    }
   ],
   "source": [
    "temp_out_dir = time.strftime('%Y%m%d%H%M%S')\n",
    "os.mkdir(temp_out_dir)\n",
    "print('创建临时文件夹 {} 用于存放每帧预测结果'.format(temp_out_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1911cfc-58b1-4121-94a9-c6e8a779f036",
   "metadata": {},
   "source": [
    "## 视频单帧预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9cd07f0-80dd-4fab-923a-719bc6ba22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 Cityscapes 街景数据集 类别名和调色板\n",
    "from mmseg.datasets import cityscapes\n",
    "classes = cityscapes.CityscapesDataset.METAINFO['classes']\n",
    "palette = cityscapes.CityscapesDataset.METAINFO['palette']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2f0568-50c6-4816-b820-cf597a5ef099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pridict_single_frame(img, opacity=0.2):\n",
    "    \n",
    "    result = inference_model(model, img)\n",
    "    \n",
    "    # 将分割图按调色板染色\n",
    "    seg_map = np.array(result.pred_sem_seg.data[0].detach().cpu().numpy()).astype('uint8')\n",
    "    seg_img = Image.fromarray(seg_map).convert('P')\n",
    "    seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "    \n",
    "    show_img = (np.array(seg_img.convert('RGB')))*(1-opacity) + img*opacity\n",
    "    \n",
    "    return show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3f5bf-f6fa-4f3b-832a-e84ce7437ed1",
   "metadata": {},
   "source": [
    "### 视频逐帧预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b53cf47-d1eb-4b77-97bd-8ce01dc3cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/159, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cine/Documents/GitHub/mmdet/mmdetection/mmdet/models/layers/positional_encoding.py:84: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/home/cine/miniconda3/envs/openmmlab-pose/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 138/138, 38.0 task/s, elapsed: 4s, ETA:     0ss[                                                  ] 0/138, elapsed: 0s, ETA:\n",
      "删除临时文件夹 20230614125150\n"
     ]
    }
   ],
   "source": [
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "\n",
    "prog_bar = mmengine.ProgressBar(len(imgs))\n",
    "\n",
    "# 对视频逐帧处理\n",
    "for frame_id, img in enumerate(imgs):\n",
    "    \n",
    "    ## 处理单帧画面\n",
    "    show_img = pridict_single_frame(img, opacity=0.15)\n",
    "    temp_path = f'{temp_out_dir}/{frame_id:06d}.jpg' # 保存语义分割预测结果图像至临时文件夹\n",
    "    cv2.imwrite(temp_path, show_img)\n",
    "\n",
    "    prog_bar.update() # 更新进度条\n",
    "\n",
    "# 把每一帧串成视频文件\n",
    "mmcv.frames2video(temp_out_dir, 'outputs/B3_video.mp4', fps=imgs.fps, fourcc='mp4v')\n",
    "\n",
    "shutil.rmtree(temp_out_dir) # 删除存放每帧画面的临时文件夹\n",
    "print('删除临时文件夹', temp_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a60b03-f55d-4e86-b336-9f562f3eb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_file = 'configs/segformer/segformer_mit-b5_8xb1-160k_cityscapes-1024x1024.py'\n",
    "checkpoint_file = 'checkpoint/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e532611-be1f-4641-b14d-850b99c3ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cine/Documents/GitHub/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/home/cine/Documents/GitHub/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: checkpoint/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import init_model\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "from mmengine.model.utils import revert_sync_batchnorm\n",
    "if not torch.cuda.is_available():\n",
    "    model = revert_sync_batchnorm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259f287d-613d-4b77-9544-0e15eb247432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建临时文件夹 20230614125925 用于存放每帧预测结果\n"
     ]
    }
   ],
   "source": [
    "temp_out_dir = time.strftime('%Y%m%d%H%M%S')\n",
    "os.mkdir(temp_out_dir)\n",
    "print('创建临时文件夹 {} 用于存放每帧预测结果'.format(temp_out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7051d3b2-5f99-4e18-8cd2-c8b5bc4ba77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 138/138, 37.5 task/s, elapsed: 4s, ETA:     0ss[                                                  ] 0/138, elapsed: 0s, ETA:\n",
      "删除临时文件夹 20230614125925\n"
     ]
    }
   ],
   "source": [
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "\n",
    "prog_bar = mmengine.ProgressBar(len(imgs))\n",
    "\n",
    "# 对视频逐帧处理\n",
    "for frame_id, img in enumerate(imgs):\n",
    "    \n",
    "    ## 处理单帧画面\n",
    "    show_img = pridict_single_frame(img, opacity=0.15)\n",
    "    temp_path = f'{temp_out_dir}/{frame_id:06d}.jpg' # 保存语义分割预测结果图像至临时文件夹\n",
    "    cv2.imwrite(temp_path, show_img)\n",
    "\n",
    "    prog_bar.update() # 更新进度条\n",
    "\n",
    "# 把每一帧串成视频文件\n",
    "mmcv.frames2video(temp_out_dir, 'outputs/B3_video_2.mp4', fps=imgs.fps, fourcc='mp4v')\n",
    "\n",
    "shutil.rmtree(temp_out_dir) # 删除存放每帧画面的临时文件夹\n",
    "print('删除临时文件夹', temp_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f3d79-b85b-480b-acda-cf8dc024cb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7aa37-d3a0-466c-a5f4-3f581f92e4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457ff32-1deb-4939-ae0e-ce1230db6932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
